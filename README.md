# ğŸ§  Aprendiendo-RL

Este repositorio documenta mi proceso de aprendizaje en **Reinforcement Learning**, abordando dos enfoques complementarios:

- âœ… **Objetivo 2:** Uso de librerÃ­as de alto nivel como `stable-baselines3` para entrenar agentes rÃ¡pidamente.
- âœ… **Objetivo 3:** ImplementaciÃ³n manual del algoritmo DQN en PyTorch, desde cero, con control total.

---

## ğŸ“‚ Estructura general del proyecto

```
Aprendiendo-RL/
â”œâ”€â”€ Objetivo 2 LunarLander/
â”‚   â”œâ”€â”€ models/              # Modelos .zip de SB3
â”‚   â”œâ”€â”€ logs/                # TensorBoard
â”‚   â”œâ”€â”€ outputs/             # GrÃ¡ficas o evaluaciones
â”‚   â””â”€â”€ tests/               # Scripts de entrenamiento y evaluaciÃ³n
â”‚
â”œâ”€â”€ Objetivo 3 DQN-desde0/
â”‚   â”œâ”€â”€ dqn_agent.py         # Clase DQN con red, buffer, entrenamiento
â”‚   â”œâ”€â”€ train_lunarlander_dqn.py  # Entrenamiento principal
â”‚   â”œâ”€â”€ eval_lunarlander_dqn.py   # EvaluaciÃ³n visual
â”‚   â”œâ”€â”€ train_dqn.py         # DQN en CartPole
â”‚   â”œâ”€â”€ eval_dqn.py          # EvaluaciÃ³n CartPole
â”‚   â”œâ”€â”€ utils.py             # GrÃ¡ficas
â”‚   â”œâ”€â”€ outputs/             # Modelos .pth y grÃ¡ficos .png
â”‚
â”œâ”€â”€ .gitignore               # Archivos a excluir del repo
â”œâ”€â”€ requirements.txt         # Dependencias del proyecto
â””â”€â”€ README.md                # Este archivo
```

---

## âœ… Objetivo 2 â€“ LunarLander con `stable-baselines3`

En esta carpeta entreno agentes en `LunarLander-v2` usando `stable-baselines3`.  
Incluye:

- Entrenamiento con DQN preconfigurado
- Uso de `VecMonitor` para logging
- VisualizaciÃ³n con TensorBoard
- Pruebas con distintos hiperparÃ¡metros
- EvaluaciÃ³n con render en `eval_lunarlander.py`

### Ejecutar un entrenamiento:
```bash
cd "Objetivo 2 LunarLander/tests"
python train_lunarlander.py
```

---

## âœ… Objetivo 3 â€“ DQN desde cero en PyTorch

AquÃ­ desarrollo una implementaciÃ³n completa de **Deep Q-Learning** sin librerÃ­as externas de RL, con Ã©nfasis en:

- Arquitectura MLP configurable
- Replay buffer manual
- Target network con `update_target()`
- PolÃ­tica epsilon-greedy (con decaimiento lineal controlado)
- Entrenamiento en `LunarLander-v2` y `CartPole-v1`

### Entrenar LunarLander:
```bash
cd "Objetivo 3 DQN-desde0"
python train_lunarlander_dqn.py
```

### Evaluar visualmente:
```bash
python eval_lunarlander_dqn.py
```

---

## ğŸ“¦ Requisitos

Instala todas las dependencias con:

```bash
pip install -r requirements.txt
```

Contenido recomendado en `requirements.txt`:

```
torch
gymnasium[box2d]
matplotlib
```

---

## ğŸ”­ PrÃ³ximos pasos

- [ ] AÃ±adir Double DQN
- [ ] Implementar Prioritized Experience Replay
- [ ] Soporte para `LunarLander-v3`
- [ ] MigraciÃ³n a entornos mÃ¡s complejos (BipedalWalker, CarRacing)
- [ ] DocumentaciÃ³n con diagramas

---

## ğŸ™‹â€â™‚ï¸ Autor

**Izanvz**  
[github.com/Izanvz](https://github.com/Izanvz)

izanvillarejo2002@gmail.com
